# Script de Scraping du Wiki Polytopia

Ce script permet de scraper le contenu du wiki Polytopia et de crÃ©er une base de connaissance structurÃ©e en fichiers Markdown.

## âš ï¸ Important - ConsidÃ©rations LÃ©gales

- Le contenu du wiki Polytopia est sous licence **CC-BY-SA**
- Vous devez **attribuer la source** lors de l'utilisation du contenu
- Respectez le fichier `robots.txt` du site
- Utilisez ce script de maniÃ¨re responsable avec un rate limiting appropriÃ©
- Le scraping intensif peut surcharger les serveurs - soyez respectueux

## ğŸ“‹ PrÃ©requis

### Installation des dÃ©pendances

```bash
pip install -r requirements_scraper.txt
```

Les bibliothÃ¨ques nÃ©cessaires sont :
- `requests` : pour les requÃªtes HTTP
- `beautifulsoup4` : pour parser le HTML
- `html2text` : pour convertir HTML en Markdown
- `lxml` : parser HTML performant

## ğŸš€ Utilisation

### Utilisation basique

```bash
python scrape_wiki.py
```

Cela scrappe jusqu'Ã  50 pages par dÃ©faut dans le dossier `wiki_knowledge/`.

### Options disponibles

```bash
# VÃ©rifier robots.txt avant de commencer
python scrape_wiki.py --check-robots

# SpÃ©cifier le nombre de pages Ã  scraper
python scrape_wiki.py --max-pages 20

# Changer le dossier de sortie
python scrape_wiki.py --output ./knowledge_base

# Ajuster le dÃ©lai entre requÃªtes (en secondes)
python scrape_wiki.py --delay 3.0

# Combiner plusieurs options
python scrape_wiki.py --max-pages 100 --delay 2.5 --output ./wiki_data
```

### Aide complÃ¨te

```bash
python scrape_wiki.py --help
```

## ğŸ“ Structure de sortie

Le script organise automatiquement les fichiers par catÃ©gories :

```
wiki_knowledge/
â”œâ”€â”€ images/              # Toutes les images tÃ©lÃ©chargÃ©es
â”œâ”€â”€ game_mechanics/      # MÃ©caniques de jeu (combat, mouvement, etc.)
â”œâ”€â”€ tribes/              # Pages des diffÃ©rentes tribus
â”œâ”€â”€ units/               # Pages des unitÃ©s
â”œâ”€â”€ technology/          # Pages des technologies
â”œâ”€â”€ buildings/           # Pages des bÃ¢timents
â”œâ”€â”€ city/                # Pages liÃ©es aux citÃ©s
â””â”€â”€ general/             # Autres pages
```

Chaque fichier Markdown contient :
- Le titre de la page
- L'URL source
- La date de scraping
- Le contenu converti en Markdown
- Les images locales (tÃ©lÃ©chargÃ©es)
- Les tableaux convertis en format Markdown

## ğŸ“ Format des fichiers gÃ©nÃ©rÃ©s

Exemple de fichier gÃ©nÃ©rÃ© :

```markdown
# Map Generation

**Source:** https://polytopia.fandom.com/wiki/Map_Generation
**Licence:** CC-BY-SA
**Date de scraping:** 2025-11-20

---

[Contenu de la page en Markdown]

---

*Ce contenu est extrait du wiki Polytopia et est sous licence CC-BY-SA.*
```

## ğŸ¯ Pages scrapÃ©es

Le script scrappe automatiquement les pages principales suivantes :

### Game Mechanics
- Map Generation
- Combat
- Movement
- Terrain
- Stars, Score, Ruins
- Game Modes

### Tribes
- Tribus gratuites : Xin-xi, Imperius, Bardur, Oumaji
- Tribus rÃ©guliÃ¨res : Kickoo, Hoodrick, Luxidoor, Vengir, Zebasi, Ai-Mo, Quetzali

### Units
- Warrior, Archer, Defender, Rider
- Swordsman, Knight, Giant

### Technology & Buildings
- Technologies principales
- BÃ¢timents (Bridge, Embassy, Temples)

### City
- City, Population, City Connection

## âš™ï¸ FonctionnalitÃ©s

âœ… **Rate limiting** : DÃ©lai configurable entre chaque requÃªte (dÃ©faut: 2s)  
âœ… **VÃ©rification robots.txt** : Option pour vÃ©rifier les rÃ¨gles de scraping  
âœ… **Organisation automatique** : Fichiers organisÃ©s par catÃ©gories  
âœ… **TÃ©lÃ©chargement d'images** : Images sauvegardÃ©es localement  
âœ… **Conversion de tableaux** : Tableaux HTML â†’ Markdown  
âœ… **MÃ©tadonnÃ©es** : Attribution et source incluses dans chaque fichier  
âœ… **Gestion d'erreurs** : Continue mÃªme si certaines pages Ã©chouent  

## ğŸ”§ Personnalisation

Pour ajouter d'autres pages Ã  scraper, modifiez la liste `main_pages` dans la mÃ©thode `scrape_from_sitemap()` du fichier `scrape_wiki.py`.

## ğŸ› DÃ©pannage

### Erreur de connexion
- VÃ©rifiez votre connexion Internet
- Le site peut Ãªtre temporairement indisponible
- Augmentez le dÃ©lai avec `--delay`

### Pages manquantes
- Certaines pages peuvent avoir une structure diffÃ©rente
- Augmentez `--max-pages` si nÃ©cessaire

### Erreurs de parsing
- Certains tableaux complexes peuvent ne pas Ãªtre parfaitement convertis
- Les images peuvent Ã©chouer si elles ne sont plus disponibles

## ğŸ“„ Licence

Ce script est fourni Ã  des fins Ã©ducatives et de recherche. Le contenu scrapy est sous licence CC-BY-SA et appartient aux contributeurs du wiki Polytopia.

## ğŸ¤ Bonnes pratiques

1. **Ne pas abuser** : Limitez le nombre de requÃªtes
2. **Respecter le dÃ©lai** : Utilisez un dÃ©lai d'au moins 2 secondes
3. **Attribuer la source** : Toujours mentionner la source originale
4. **Usage responsable** : Utilisez les donnÃ©es de maniÃ¨re Ã©thique
5. **VÃ©rifier robots.txt** : Assurez-vous que le scraping est autorisÃ©

---

Pour toute question ou problÃ¨me, rÃ©fÃ©rez-vous Ã  la documentation de Fandom ou contactez les maintenteurs du wiki.


